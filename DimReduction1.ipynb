{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DimReduction1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNznQuCZSFU74rj80Bi7H/K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robcovino/MSDAP_notebooks/blob/main/DimReduction1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Dimensionality reduction -- Principal component analysis\n",
        "\n",
        "In this section, we explore what is perhaps one of the most broadly used of unsupervised algorithms, principal component analysis (PCA).\n",
        "PCA is fundamentally a dimensionality reduction algorithm, but it can also be useful as a tool for visualization, for noise filtering, for feature extraction and engineering, and much more.\n",
        "After a brief conceptual discussion of the PCA algorithm, we will see a couple examples of these further applications."
      ],
      "metadata": {
        "id": "42dX9RxXmJXg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgOh9m6TmHY0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Introducing Principal Component Analysis\n",
        "\n",
        "Principal component analysis is a fast and flexible unsupervised method for dimensionality reduction in data.\n",
        "Its behavior is easiest to visualize by looking at a two-dimensional dataset.\n",
        "Consider the following 200 points:"
      ],
      "metadata": {
        "id": "ZARf0ZR7mbc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.RandomState(1)\n",
        "X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T\n",
        "plt.scatter(X[:, 0], X[:, 1])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "3820DZWome5N",
        "outputId": "ae73ba02-c37b-411a-bf78-612b0ce381e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Work out what we did to generate the random cloud of 2d data.\n",
        "\n",
        "Q2. What is the intrinsic dimensionality of the data? \n",
        "\n",
        "In principal component analysis, this relationship is quantified by finding a list of the *principal axes* in the data, and using those axes to describe the dataset.\n",
        "\n",
        "Q3. Use Scikit-Learn's ``PCA`` estimator to calculate the principal components. Use <b> n_components=2 </b>."
      ],
      "metadata": {
        "id": "UyOhwC2Vm8i1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n"
      ],
      "metadata": {
        "id": "-eH0-EPVnQ5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fit learns some quantities from the data, most importantly the \"components\" and \"explained variance\":"
      ],
      "metadata": {
        "id": "yrEBwj4yol1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pca.components_)"
      ],
      "metadata": {
        "id": "6xdCSyxqok8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pca.explained_variance_)"
      ],
      "metadata": {
        "id": "N1rKp4EbopAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see what these numbers mean, let's visualize them as vectors over the input data, using the \"components\" to define the direction of the vector, and the \"explained variance\" to define the squared-length of the vector:"
      ],
      "metadata": {
        "id": "DZtzijvvo60n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_vector(v0, v1, ax=None):\n",
        "    ax = ax or plt.gca()\n",
        "    arrowprops=dict(arrowstyle='->',\n",
        "                    linewidth=2,\n",
        "                    shrinkA=0, shrinkB=0)\n",
        "    ax.annotate('', v1, v0, arrowprops=arrowprops)\n",
        "\n",
        "# plot data\n",
        "plt.scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
        "for length, vector in zip(pca.explained_variance_, pca.components_):\n",
        "    v = vector * 3 * np.sqrt(length)\n",
        "    draw_vector(pca.mean_, pca.mean_ + v)\n",
        "plt.axis('equal');"
      ],
      "metadata": {
        "id": "wgx530pKoqGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These vectors represent the *principal axes* of the data, and the length of the vector is an indication of how \"important\" that axis is in describing the distribution of the dataâ€”more precisely, it is a measure of the variance of the data when projected onto that axis.\n",
        "The projection of each data point onto the principal axes are the \"principal components\" of the data.\n",
        "\n",
        "This transformation from data axes to principal axes is an *affine transformation*, which basically means it is composed of a translation, rotation, and uniform scaling.\n",
        "\n",
        "While this algorithm to find principal components may seem like just a mathematical curiosity, it turns out to have very far-reaching applications in the world of machine learning and data exploration.\n",
        "\n",
        "---\n",
        "### PCA as dimensionality reduction\n",
        "\n",
        "Using PCA for dimensionality reduction involves zeroing out one or more of the smallest principal components, resulting in a lower-dimensional projection of the data that preserves the maximal data variance.\n",
        "\n",
        "Q4. Use the previous example to obtain a reduced version of the same dataset. "
      ],
      "metadata": {
        "id": "d4C2LEBZpMLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Sq02HmaJpLCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Plot the original and reduced data set to assess how much information you lost. Note that you will have to project or <b> lift </b> the data from the reduced-dimensional representation back to the full dimensional one."
      ],
      "metadata": {
        "id": "M2Q6MSdNzq4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Gu9GgM-hzieK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### PCA for visualization: Hand-written digits\n",
        "\n",
        "The usefulness of the dimensionality reduction may not be entirely apparent in only two dimensions, but becomes much more clear when looking at high-dimensional data.\n",
        "To see this, let's take a quick look at the application of PCA to the digits data"
      ],
      "metadata": {
        "id": "0HrvVG-Q0vpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the digit data\n",
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "digits.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IWZqm6jzlGU",
        "outputId": "39752032-1bf4-426d-b54b-70707af45feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Give a look at the data and understand how they are organized. Helpyourself with the plt.imshow function to plot some of the data entries."
      ],
      "metadata": {
        "id": "whCz6uYy1Mo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "v8nLv3-704P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. What is the dimensionality of these data? Use PCA to extract a 2d representation of the data set."
      ],
      "metadata": {
        "id": "VyUqX20b1w7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LKEEqNWX1Skn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. Adapt the code below to plot the 2dimensional embedding of the digits data set. Discuss the quality of the embedding. An important step is always to check whether the data you got make visual/intuitive sense, and whether they are what you would expect or if instead they are very surprising. "
      ],
      "metadata": {
        "id": "yVcY7dBK3RiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9, 8))\n",
        "plt.scatter(,\n",
        "            c=digits.target, edgecolor='none', alpha=0.5,\n",
        "            cmap=plt.cm.get_cmap('nipy_spectral', 10))\n",
        "plt.xlabel('component 1')\n",
        "plt.ylabel('component 2')\n",
        "plt.colorbar();"
      ],
      "metadata": {
        "id": "MFpHKgfF130-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choosing the number of components\n",
        "\n",
        "A vital part of using PCA in practice is the ability to estimate how many components are needed to describe the data.\n",
        "This can be determined by looking at the cumulative *explained variance ratio* as a function of the number of components.\n",
        "\n",
        "Q8. Plot the cumulative explained variance ratio as a function of the components you keep. Do you think that keeping 2 was a good choice? "
      ],
      "metadata": {
        "id": "88N2HgAb4JQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA().fit(digits.data)\n"
      ],
      "metadata": {
        "id": "c3RY-J8m1_EA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## PCA as Noise Filtering\n",
        "\n",
        "PCA can also be used as a filtering approach for noisy data.\n",
        "The idea is this: any components with variance much larger than the effect of the noise should be relatively unaffected by the noise.\n",
        "So if you reconstruct the data using just the largest subset of principal components, you should be preferentially keeping the signal and throwing out the noise.\n",
        "\n",
        "Let's see how this looks with the digits data.\n",
        "First we will plot several of the input noise-free data.\n",
        "\n",
        "Q9. Insert the data in the plotting function below."
      ],
      "metadata": {
        "id": "B_gtOK7v4kL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_digits(data):\n",
        "    fig, axes = plt.subplots(4, 10, figsize=(10, 4),\n",
        "                             subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                             gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(,\n",
        "                  cmap='binary', interpolation='nearest',\n",
        "                  clim=(0, 16))\n",
        "plot_digits(digits.data)"
      ],
      "metadata": {
        "id": "HODnZ3Y84oc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#np.random.seed(42)\n",
        "noisy = np.random.normal(digits.data, 4)\n",
        "plot_digits(noisy)"
      ],
      "metadata": {
        "id": "g-w3tCGj4sC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. Train PCA on the noisy data set, and keep 50% of the total variance. How many component are necessary for this?"
      ],
      "metadata": {
        "id": "D0tPCKBO5IrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF8k0sM04x9l",
        "outputId": "f4b6746e-063d-47d8-e042-610413ee278b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea is that by reproducing only the bulk of the variance, we will filter out unenecessary noice from the data. To do this, you must project the original data into the low-dimensional embedding, and then lift them back.\n",
        "\n",
        "Q11. Use PCA to remove the noise from the noisy digit data set we just created."
      ],
      "metadata": {
        "id": "v5JWbDRT5X-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zgmWl_OA5SHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Introducing the Swiss Roll\n",
        "\n",
        "Using the code below, generate the next data structure on which to work, which is known as the <b> swiss roll </b>."
      ],
      "metadata": {
        "id": "L5zhKpvd7Ty2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def swiss_roll_2d( n_sample=1000, noise=0.1 ):\n",
        "  from numpy.random import normal\n",
        "  theta = np.linspace(0, 3 * np.pi, n_sample)\n",
        "  R = np.linspace(1, 5, n_sample)\n",
        "  X = R * np.cos(theta) + normal(scale=noise, size=n_sample)\n",
        "  Y = R * np.sin(theta) + normal(scale=noise, size=n_sample)\n",
        "  return np.hstack((X.reshape(-1,1), Y.reshape(-1,1)))"
      ],
      "metadata": {
        "id": "-UsS5vOu6H4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11 How are these data organized? Plot them. What does the <b> noise </b> parameter control?"
      ],
      "metadata": {
        "id": "beImpk1U7ciA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uYU1025U7b_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12. What is the intrinsic dimensionality of these data? Try to use the sklearn PCA to perfom dimensionality reduction. Hint: color the original 2d swiss role data according to the 1d PCA variable you discovered. How many PCA components do you need to explain the variance contained in the data set?"
      ],
      "metadata": {
        "id": "ezkNQKwf7n_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PWDeRQtl7jBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Dt-Ksn0M7smt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "54eQJxYY7uTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SeJevYLq7wgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13. Was your dimensionality reduction succesful? Can you explain why?"
      ],
      "metadata": {
        "id": "gRRusPMy75hw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is based on https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.09-Principal-Component-Analysis.ipynb#scrollTo=tn_wtxGXgGVY"
      ],
      "metadata": {
        "id": "9bW6wtgF79dA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aLPU306H7ySi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}