{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clustering2 - Hierarchical.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjfqM6D4RjauoF0s5JkMGJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robcovino/MSDAP_notebooks/blob/main/Clustering2_Hierarchical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Hierarchical clustering\n",
        "\n"
      ],
      "metadata": {
        "id": "pJII9rEzXZ38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "o6UTa7cXYFYp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Generating Random Data\n",
        "Using the code developed in the previous notebook, use make_blobs to produce some synthetic data:\n",
        "<ul>\n",
        "    <li> <b>n_samples</b>: The total number of points equally divided among clusters. </li>\n",
        "    <ul> <li> Choose a number from 10-1500 </li> </ul>\n",
        "    <li> <b>centers</b>: The number of centers to generate, or the fixed center locations. </li>\n",
        "    <ul> <li> Choose arrays of x,y coordinates for generating the centers. Have 1-10 centers (ex. centers=[[1,1], [2,5]]) </li> </ul>\n",
        "    <li> <b>cluster_std</b>: The standard deviation of the clusters. The larger the number, the further apart the clusters</li>\n",
        "    <ul> <li> Choose a number between 0.5-1.5 </li> </ul>\n",
        "</ul> <br>\n",
        "Save the result to <b>X1</b> and <b>y1</b>."
      ],
      "metadata": {
        "id": "dvXjxgEu3UM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JnGrD6wlYUPc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What data do X1 and y1 contain? Plot the scatter plot of the randomly generated data"
      ],
      "metadata": {
        "id": "zYRdKtBs3qyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Je_nAAOotAGk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. How would you visually cluster these data and why?"
      ],
      "metadata": {
        "id": "IQVfMKFf9XBX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Agglomerative Clustering\n",
        "We will start by clustering the random data points we just created."
      ],
      "metadata": {
        "id": "4JPA8wTV3zAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The <b> Agglomerative Clustering </b> class from sklearn will require two inputs:\n",
        "<ul>\n",
        "    <li> <b>n_clusters</b>: The number of clusters to form as well as the number of centroids to generate. </li>\n",
        "    <li> <b>linkage</b>: Which linkage criterion to use. The linkage criterion determines which distance to use between sets of observation. The algorithm will merge the pairs of cluster that minimize this criterion. </li>\n",
        "    <ul> \n",
        "        <li> Value will be: 'complete' </li> \n",
        "        <li> <b>Note</b>: It is recommended you try everything with 'average' as well </li>\n",
        "    </ul>\n",
        "</ul> <br>\n",
        "Save the result to a variable called <b> agglom </b>"
      ],
      "metadata": {
        "id": "C_quXm8v32RB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Modify the <b> n_clusters </b> parameter and check if agglomerative clustering agrees with your initial guess."
      ],
      "metadata": {
        "id": "8l0SekCx_cx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering \n",
        "\n",
        "agglom = AgglomerativeClustering(n_clusters = 3, linkage = 'average')"
      ],
      "metadata": {
        "id": "uP0XoRyt3sla"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the model with <b> X1 </b>from the generated data above.\n"
      ],
      "metadata": {
        "id": "oefjeMjy4MXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agglom.fit(X1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apzl_gbM4J88",
        "outputId": "8678a037-7c9e-4f71-bee7-61630c539d4e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgglomerativeClustering(linkage='average', n_clusters=3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure of size 6 inches by 4 inches.\n",
        "plt.figure(figsize=(6,4))\n",
        "\n",
        "# These two lines of code are used to scale the data points down,\n",
        "# Or else the data points will be scattered very far apart.\n",
        "\n",
        "# Create a minimum and maximum range of X1.\n",
        "x_min, x_max = np.min(X1, axis=0), np.max(X1, axis=0)\n",
        "\n",
        "# Get the average distance for X1.\n",
        "X1 = (X1 - x_min) / (x_max - x_min)\n",
        "\n",
        "# This loop displays all of the datapoints.\n",
        "for i in range(X1.shape[0]):\n",
        "    # Replace the data points with their respective cluster value \n",
        "    # (ex. 0) and is color coded with a colormap (plt.cm.spectral)\n",
        "    plt.text(X1[i, 0], X1[i, 1], str(y1[i]),\n",
        "             color=plt.cm.nipy_spectral(agglom.labels_[i] / 10.),\n",
        "             fontdict={'weight': 'bold', 'size': 9})\n",
        "    \n",
        "# Remove the x ticks, y ticks, x and y axis\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "#plt.axis('off')\n",
        "\n",
        "\n",
        "\n",
        "# Display the plot of the original data before clustering\n",
        "plt.scatter(X1[:, 0], X1[:, 1], marker='.')\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "upeomcc_4OtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Redo the agglomerative clustering playing with the <b> n_clusters </b> parameter. Can you sketch the order with which the algoritm merges the various clusters (clustering hierarchy)?"
      ],
      "metadata": {
        "id": "_X2LZ9Fh_80g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dendrogram Associated for the Agglomerative Hierarchical Clustering\n",
        "Remember that a <b>distance matrix</b> contains the <b> distance from each point to every other point of a dataset </b>. <br>\n",
        "Use the function <b> distance_matrix, </b> which requires <b>two inputs</b>. Use the Feature Matrix, <b> X2 </b> as both inputs and save the distance matrix to a variable called <b> dist_matrix </b> <br> <br>\n",
        "Remember that the distance values are symmetric, with a diagonal of 0's. This is one way of making sure your matrix is correct. <br> (print out dist_matrix to make sure it's correct)"
      ],
      "metadata": {
        "id": "BPLB1QLk4ccg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance_matrix \n",
        "\n",
        "dist_matrix = distance_matrix(X1,X1) \n",
        "print(dist_matrix)"
      ],
      "metadata": {
        "id": "I2TfNaLE4VVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the <b> linkage </b> class from hierarchy, pass in the parameters:\n",
        "<ul>\n",
        "    <li> The distance matrix </li>\n",
        "    <li> 'complete' for complete linkage </li>\n",
        "</ul> <br>\n",
        "Save the result to a variable called <b> Z </b>"
      ],
      "metadata": {
        "id": "vAHGiGXc4vGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster import hierarchy\n",
        "\n",
        "Z = hierarchy.linkage(dist_matrix, 'complete')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88OAwqqb4oUA",
        "outputId": "046b5484-2ad5-406b-abad-4f739c7610e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Hierarchical clustering is typically visualized as a dendrogram as shown in the following cell. Each merge is represented by a horizontal line. The y-coordinate of the horizontal line is the similarity of the two clusters that were merged, where cities are viewed as singleton clusters. \n",
        "By moving up from the bottom layer to the top node, a dendrogram allows us to reconstruct the history of merges that resulted in the depicted clustering. \n",
        "\n",
        "Next, we will save the dendrogram to a variable called <b>dendro</b>. In doing this, the dendrogram will also be displayed.\n",
        "Using the <b> dendrogram </b> class from hierarchy, pass in the parameter:\n",
        "<ul> <li> Z </li> </ul>"
      ],
      "metadata": {
        "id": "yMDFVktC5AKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dendro = hierarchy.dendrogram(Z)"
      ],
      "metadata": {
        "id": "s6PGdOB34x98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Does this dendrogram correspond to what you sketched for the previous question? Check how the dedrogram changes as a function of the clustering method. "
      ],
      "metadata": {
        "id": "cjMFeb635TxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Clustering on Vehicle dataset\n",
        "\n",
        "Imagine that an automobile manufacturer has developed prototypes for a new vehicle. Before introducing the new model into its range, the manufacturer wants to determine which existing vehicles on the market are most like the prototypes--that is, how vehicles can be grouped, which group is the most similar with the model, and therefore which models they will be competing against.\n",
        "\n",
        "Our objective here, is to use clustering methods, to find the most distinctive clusters of vehicles. It will summarize the existing vehicles and help manufacture to make decision about new models simply."
      ],
      "metadata": {
        "id": "rbtKXkrS5w9q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download data\n",
        "To download the data, we will use **`!wget`**. To download the data, we will use `!wget` to download it from IBM Object Storage. "
      ],
      "metadata": {
        "id": "UW5ZH8KF54IS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O cars_clus.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/cars_clus.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f01VR5mZ5Hng",
        "outputId": "edff980b-bdff-44db-bfd8-ecace4489437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-20 15:17:32--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/cars_clus.csv\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17774 (17K) [text/csv]\n",
            "Saving to: ‘cars_clus.csv’\n",
            "\n",
            "cars_clus.csv       100%[===================>]  17.36K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-03-20 15:17:33 (147 MB/s) - ‘cars_clus.csv’ saved [17774/17774]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data\n",
        "lets read dataset to see what features the manufacturer has collected about the existing models. To do this, we will use the pandas python library, which is the standard library to manipulate large data sets."
      ],
      "metadata": {
        "id": "vuAz5K4v5_V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "filename = 'cars_clus.csv'\n",
        "\n",
        "#Read csv\n",
        "pdf = pd.read_csv(filename)\n",
        "print (\"Shape of dataset: \", pdf.shape)\n",
        "\n",
        "pdf.head(5)"
      ],
      "metadata": {
        "id": "iqvbd9MU56vM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning\n",
        "A large part of the job of a data scientist is cleaning the data before doing any analysis.\n",
        "\n",
        "Q6. Can you understand what the code below is doing?"
      ],
      "metadata": {
        "id": "ga8Fhnde6Tb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Shape of dataset before cleaning: \", pdf.size)\n",
        "pdf[[ 'sales', 'resale', 'type', 'price', 'engine_s',\n",
        "       'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap',\n",
        "       'mpg', 'lnsales']] = pdf[['sales', 'resale', 'type', 'price', 'engine_s',\n",
        "       'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap',\n",
        "       'mpg', 'lnsales']].apply(pd.to_numeric, errors='coerce')\n",
        "pdf = pdf.dropna()\n",
        "pdf = pdf.reset_index(drop=True)\n",
        "print (\"Shape of dataset after cleaning: \", pdf.size)\n",
        "pdf.head(5)"
      ],
      "metadata": {
        "id": "O6ndr0Vj6C5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection\n",
        "Lets select our feature set:"
      ],
      "metadata": {
        "id": "f3XteIhL6opT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featureset = pdf[['engine_s',  'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap', 'mpg']]"
      ],
      "metadata": {
        "id": "4Hn_2j426Z-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalization\n",
        "Now we can normalize the feature set. __MinMaxScaler__ transforms features by scaling each feature to a given range. It is by default (0, 1). That is, this estimator scales and translates each feature individually such that it is between zero and one.\n",
        "\n",
        "Q7. Why do we actually need to do this?"
      ],
      "metadata": {
        "id": "UIyclL436uWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "x = featureset.values #returns a numpy array\n",
        "min_max_scaler = MinMaxScaler()\n",
        "feature_mtx = min_max_scaler.fit_transform(x)\n",
        "feature_mtx [0:5]"
      ],
      "metadata": {
        "id": "B70fwsnG6wjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering using Scipy\n",
        "In this part we use Scipy agglomerative clustering to cluster the dataset:  \n",
        "Q8. First, we calculate the pairwise distance matrix. Hint. Check whay scipy.spatial.distance has to offer.\n",
        "\n",
        "Q9. Is your distance matrix symmetric? How can you easily check that in numpy?"
      ],
      "metadata": {
        "id": "cN0orcwS67ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AUgUW0KfCUWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. Looking at the code we used above, use scipy to perform an agglomerative clustering with the distance matrix you just calculated."
      ],
      "metadata": {
        "id": "3LrJtE6KBykw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2lYCabNR7CNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hierarchical clustering does not require a pre-specified number of clusters. However, in some applications we want a partition of disjoint clusters just as in flat clustering. So you can use a cutting line:"
      ],
      "metadata": {
        "id": "OneX2W217gow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import fcluster\n",
        "max_d = 3\n",
        "clusters = fcluster(Z, max_d, criterion='distance')\n",
        "clusters"
      ],
      "metadata": {
        "id": "3NfFXmw77Yvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, you can determine the number of clusters directly:"
      ],
      "metadata": {
        "id": "076FRMY07lNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import fcluster\n",
        "k = 5\n",
        "clusters = fcluster(Z, k, criterion='maxclust')\n",
        "clusters"
      ],
      "metadata": {
        "id": "-NlVWLG07dI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can plot the dendrogram"
      ],
      "metadata": {
        "id": "9P-f-2Eu7wDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(18,30))\n",
        "def llf(id):\n",
        "    return '[%s %s %s]' % (pdf['manufact'][id], pdf['model'][id], int(float(pdf['type'][id])) )\n",
        "    \n",
        "dendro = hierarchy.dendrogram(Z,  leaf_label_func=llf, leaf_rotation=0, leaf_font_size =12, orientation = 'right')"
      ],
      "metadata": {
        "id": "-gG3xkOd7nXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebook adapted from: https://colab.research.google.com/github/Gurubux/CognitiveClass-ML/blob/master/Course_MachineLearningWithPython/5-Clustering/ML0101EN-Clus-Hierarchical-Cars-py-v1.ipynb#scrollTo=8GgMW0CiABdR"
      ],
      "metadata": {
        "id": "yxsI4-D08EfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YMXgPUlr76hu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}